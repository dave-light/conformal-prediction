{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, implementation of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Loading data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load iris data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now importing ionosphere data\n",
    "\n",
    "#34 features so usecols=np.arrange(34) take first 34 as column\n",
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=np.arange(34))\n",
    "\n",
    "#each label is of type int, features are not. Only labels will be generated\n",
    "y = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "usecols=34, dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "Splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(iris['data'],\n",
    "iris['target'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split ionosphere\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y, random_state=23) #random state 23 yileds lower false-p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fit(features, labels):\n",
    "\n",
    "    columns = features.shape[1] + 1\n",
    "    length = len(features)\n",
    "    labelled_samples = np.zeros((length,columns))\n",
    "    for x in range(length):\n",
    "        labelled_samples[x] = np.concatenate([features[x], [labels[x]]])\n",
    "    return labelled_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "Implementing the Nearest Neighbour method. \n",
    "\n",
    "Reasoning; the average difference between all 34 features in ionoshpere provides x co-ordinate (4 features for iris). The euclidean distance is calculated using x value and x* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"takes two vectors sample[x,y] and neighbour[x,y]\n",
    "   takes one scalar 'l' of type int, limiting number of attributes i.e. not including labels\n",
    "\"\"\"\n",
    "#calculates euclidean distance\n",
    "def distance(x1, x2, num_of_features):\n",
    "    distance = 0\n",
    "    for i in range(num_of_features):\n",
    "        distance += ((x1[i] - x2[i])**2)\n",
    "    return math.sqrt(distance)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds distance from nearest neighbour \n",
    "\n",
    "def calc_nearest(distance_list):\n",
    "    current_minimum = math.inf\n",
    "    length = len(distance_list)\n",
    "    index = math.inf\n",
    "    for x in range(length):\n",
    "        if current_minimum > distance_list[x]:\n",
    "            current_minimum = distance_list[x]\n",
    "            index = x\n",
    "    return index #returns index of min distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "\n",
    "def predict(test_sample, train_set, num_of_features):\n",
    "    distance_list = []\n",
    "    length = len(train_set)\n",
    "    for x in range(length):\n",
    "        #calls distance() and appends to distance_list\n",
    "        distance_list.append(distance(test_sample, train_set[x], num_of_features))\n",
    "    nearest_neighbour = calc_nearest(distance_list) #index of neareset neighbour in training set \n",
    "    predicted_label = train_set[nearest_neighbour][-1]\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERROR RATE\n",
    "def test_error_rate(predictions, actual_labels):\n",
    "    return np.mean(predictions != actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformity Measure\n",
    "the divide(a, b) function in the cell below returns the conformity score\n",
    "\n",
    "* **0/x = 0**\n",
    "\n",
    "* **x/0 = infinity**\n",
    "\n",
    "* **0/0 = 0** returns an average false p-value of 0.04\n",
    "\n",
    "* **0/0 = 1** the average false p-value for Iris improves from 0.04 to 0.01, hence I have chosen this. It is also mathematically sound in that x/x = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(numerator, denominator):\n",
    "\n",
    "    if numerator and denominator == 0:\n",
    "        return 1\n",
    "    elif numerator == 0:\n",
    "        return 0\n",
    "    elif denominator == 0:\n",
    "        return math.inf\n",
    "    else:\n",
    "        return numerator/denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate confirmity scores for entire training set\n",
    "Calculate the scores for the whole training set and store them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFORMITY SCORES\n",
    "def conformity(neighbours_set, num_features):\n",
    "\n",
    "    length = len(neighbours_set)\n",
    "    conformity_scores = []\n",
    "    for x in range(length):\n",
    "        n = 0\n",
    "        distance_list = []\n",
    "        distance_to_diff = 1\n",
    "        diff_flag = 0\n",
    "        distance_to_same = 1\n",
    "        same_flag = 0\n",
    "        conf_score = 0\n",
    "        for i in range(length):\n",
    "            if x == i:\n",
    "                n = i #store the index of the neighbour being operated on\n",
    "            distance_list.append(distance(neighbours_set[x], neighbours_set[i], num_features))\n",
    "        \n",
    "        current_minimum = math.inf\n",
    "        index = 0 #index of nearest neighbour\n",
    "        for j in range(length):\n",
    "            if current_minimum > distance_list[j]:\n",
    "                if j != n: #ensure not storing distance to itself\n",
    "                    current_minimum = distance_list[j]\n",
    "                    index = j\n",
    "            \n",
    "        if neighbours_set[index][-1] == neighbours_set[x][-1]:\n",
    "            distance_to_same = current_minimum\n",
    "            same_flag = 1\n",
    "\n",
    "        else:\n",
    "            distance_to_diff = current_minimum\n",
    "            diff_flag = 1\n",
    "\n",
    "        \n",
    "        if same_flag == 1:\n",
    "            current_minimum = math.inf\n",
    "            for j in range(length):\n",
    "                if current_minimum > distance_list[j]:\n",
    "                    if j != n and neighbours_set[j][-1] != neighbours_set[x][-1]: #ensure labels aren't the same\n",
    "                        current_minimum = distance_list[j]\n",
    "            distance_to_diff = current_minimum\n",
    "\n",
    "        \n",
    "        if diff_flag == 1:\n",
    "            current_minimum = math.inf\n",
    "            for j in range(length):\n",
    "                if current_minimum > distance_list[j]:\n",
    "                    if j != n and neighbours_set[j][-1] == neighbours_set[x][-1]: #ensure labels are the same\n",
    "                        current_minimum = distance_list[j]            \n",
    "            distance_to_same = current_minimum\n",
    "\n",
    "        conf_score = divide(distance_to_diff, distance_to_same)\n",
    "        conformity_scores.append(conf_score)\n",
    "\n",
    "    return conformity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p-value\n",
    "Re-compute conformity score for single test_sample\\[label\\], the nearest neighbour of the same, and the nearest neighbour of different. \n",
    "\n",
    "Rank *test_sample\\[label\\]*\n",
    "\n",
    "Return *rank  /  n +1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_p_val(conformity_set, train_set, p_training_set):   \n",
    "    #shape of training_set arr[item][features, features, label, conformity_score]\n",
    "    \n",
    "    #CALCULATE NEW CONFORMITY SCORE FOR ADDED LABEL\n",
    "        #if p_training_set[x][-1] == p_training_set[-1][-1]\n",
    "    \n",
    "    length = len(conformity_set) #length of original set. Ignores test_item \n",
    "    conformity_score_for_label = 0\n",
    "    num_features = len(train_set[0])-1\n",
    "    \n",
    "    distance_list = []\n",
    "    distance_to_diff = 1\n",
    "    diff_flag = 0\n",
    "    distance_to_same = 1\n",
    "    same_flag = 0\n",
    "    conf_score = 0\n",
    "    for i in range(length):\n",
    "        distance_list.append(distance(train_set[i], p_training_set[-1], num_features))\n",
    "\n",
    "    current_minimum = math.inf\n",
    "    index = 0 #index of nearest neighbour\n",
    "    for j in range(length):\n",
    "        if current_minimum > distance_list[j]:\n",
    "            current_minimum = distance_list[j]\n",
    "            index = j\n",
    "\n",
    "    if train_set[index][-1] == p_training_set[-1][-1]:\n",
    "        distance_to_same = current_minimum\n",
    "        same_flag = 1\n",
    "\n",
    "    else:\n",
    "        distance_to_diff = current_minimum\n",
    "        diff_flag = 1\n",
    "\n",
    "    index_to_same = 0\n",
    "    index_to_diff = 0\n",
    "    if same_flag == 1:\n",
    "        index_to_same = index\n",
    "        current_minimum = math.inf\n",
    "        for j in range(length):\n",
    "            if current_minimum > distance_list[j]:\n",
    "                if train_set[j][-1] != p_training_set[-1][-1]: #ensure labels aren't the same\n",
    "                    current_minimum = distance_list[j]\n",
    "                    index_to_diff = j\n",
    "        distance_to_diff = current_minimum\n",
    "\n",
    "\n",
    "    if diff_flag == 1:\n",
    "        index_to_diff = index\n",
    "        current_minimum = math.inf\n",
    "        for j in range(length):\n",
    "            if current_minimum > distance_list[j]:\n",
    "                if train_set[j][-1] == p_training_set[-1][-1]: #ensure labels are the same\n",
    "                    current_minimum = distance_list[j]\n",
    "                    index_to_same = j\n",
    "        distance_to_same = current_minimum\n",
    "\n",
    "    conf_score = divide(distance_to_diff, distance_to_same)\n",
    "    #update conformity set\n",
    "    \n",
    "    rank = length+1\n",
    "    for x in range(length):\n",
    "        if conf_score <= conformity_set[x]:\n",
    "            rank -= 1\n",
    "    \n",
    "    rank /= (length +1)\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate false p-value\n",
    "Sum total p-values ignoring p_value of true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate false p value for each sample\n",
    "\n",
    "def p_val(conformity_set, train_set, test_sample, labels_set,  true_label):\n",
    "    average_p = 0\n",
    "    \n",
    "    l = len(labels_set)\n",
    "\n",
    "    train_set_plus1 = len(train_set)+1\n",
    "    \n",
    "    false_p = 0\n",
    "    for i in range(len(labels_set)):\n",
    "        p_training_set = np.empty(train_set.shape)\n",
    "        test_sample[-1]=labels_set[i]\n",
    "        p_training_set = np.concatenate([train_set, [test_sample]])\n",
    "        new_p = calculate_p_val(conformity_set, train_set, p_training_set)\n",
    "        if true_label != labels_set[i]:\n",
    "            false_p += new_p\n",
    "    average_p = false_p / (l-1)\n",
    "    return average_p #(per row of samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error rate: 0.02631578947368421\n",
      "\n",
      "average false p value 0.011178388448998608\n",
      "Iris ran in  0.15470170974731445  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#constants\n",
    "num_of_features = len(X_test_iris[0])\n",
    "num_of_samples = len(y_test_iris)\n",
    "actual_labels = y_test_iris\n",
    "#train \n",
    "iris_train_set = knn_fit(X_train_iris, y_train_iris)\n",
    "iris_test_set = knn_fit(X_test_iris, y_test_iris)\n",
    "\n",
    "#predict\n",
    "predictions = []\n",
    "for x in range(num_of_samples):\n",
    "    predictions.append(int(predict(iris_test_set[x], iris_train_set, num_of_features)))\n",
    "\n",
    "\n",
    "# SCORE\n",
    "print('test error rate: '+str(test_error_rate(predictions, actual_labels))+'\\n')\n",
    "\n",
    "# Calculate conformity scores for iris_train_set\n",
    "conformity_set = conformity(iris_train_set, num_of_features)\n",
    "\n",
    "\n",
    "labels_set = [0,1,2]\n",
    "iris_test_set_labels = iris_test_set\n",
    "false_p_value =0\n",
    "temp_p_value = 0\n",
    "\n",
    "# for all predictions, append false p values for all test samples\n",
    "for x in range(len(predictions)):\n",
    "    temp_p_value += p_val(conformity_set, iris_train_set, iris_test_set[x], labels_set, actual_labels[x])\n",
    "false_p_value = (temp_p_value / len(predictions))\n",
    "\n",
    "print('average false p value '+str(false_p_value))\n",
    "print('Iris ran in ',time.time() - start, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IONESPHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error rate: 0.07954545454545454\n",
      "\n",
      "average false p value 0.04739152892561988\n",
      "Ionosphere ran in  2.905355453491211  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#constants\n",
    "num_of_features = len(X_test[0])\n",
    "num_of_samples = len(y_test)\n",
    "actual_labels = y_test\n",
    "#train \n",
    "iono_train_set = knn_fit(X_train, y_train)\n",
    "iono_test_set = knn_fit(X_test, y_test)\n",
    "\n",
    "#predict\n",
    "predictions = []\n",
    "for x in range(num_of_samples):\n",
    "    predictions.append(int(predict(iono_test_set[x], iono_train_set, num_of_features)))\n",
    "\n",
    "\n",
    "# SCORE\n",
    "print('test error rate: '+str(test_error_rate(predictions, actual_labels))+'\\n')\n",
    "\n",
    "# Calculate conformity scores for iono_train_set\n",
    "conformity_set = conformity(iono_train_set, num_of_features)\n",
    "\n",
    "labels_set = [1,-1]\n",
    "false_p_value =0\n",
    "temp_p_value = 0\n",
    "\n",
    "# for all predictions, append false p values for all test samples\n",
    "for x in range(len(predictions)):\n",
    "    temp_p_value += p_val(conformity_set, iono_train_set, iono_test_set[x], labels_set, actual_labels[x])\n",
    "false_p_value = (temp_p_value / len(predictions))\n",
    "\n",
    "print('average false p value '+str(false_p_value))\n",
    "print('Ionosphere ran in ',time.time() - start, ' seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
