{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inductive Conformal Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, random_state=1201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36801497049625675"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train,y_train)\n",
    "lasso.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3528762069100633"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Training R^2 for the Lasso model, lasso score: 0.36801497049625675\n",
    "+ Test R^2 for the Lasso model, lasso score: 0.4736545705189427\n",
    "+ There are 10 features\n",
    "+ The feature names are: 'age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"diabetes.data\", delimiter=\"\t\", skip_header = 1,\n",
    "usecols=np.arange(10),)\n",
    "\n",
    "y = np.genfromtxt(\"diabetes.data\", delimiter=\"\t\", skip_header = 1,\n",
    "usecols=10, dtype='int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = np.genfromtxt('diabetes.data',  skip_header = 1,\n",
    "usecols=np.arange(10),)\n",
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.    ,   2.    ,  32.1   , 101.    , 157.    ,  93.2   ,\n",
       "         38.    ,   4.    ,   4.8598,  87.    ],\n",
       "       [ 48.    ,   1.    ,  21.6   ,  87.    , 183.    , 103.2   ,\n",
       "         70.    ,   3.    ,   3.8918,  69.    ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518311821269729"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso().fit(X_train, y_train)\n",
    "lasso.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4736545705189427"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are 10 features for the diabetes.data file\n",
    "+ The feature names are AGE\tSEX\tBMI\tBP\tS1\tS2\tS3\tS4\tS5\tS6\n",
    "+ The lasso training score is 0.518311821269729\n",
    "+ The lasso teset score is \n",
    "\n",
    "The lasso score is the same on the tes set but different on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331, 10)\n",
      "(111, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7 \n",
    "(Note to self, using two seperate scalars is a perfect example of data snooping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48660309, -0.9048101 ,  0.23994961, ..., -0.02266782,\n",
       "         0.55554925, -0.0755863 ],\n",
       "       [ 0.80307313,  1.10520428, -0.52093878, ..., -0.79300119,\n",
       "        -0.31573303, -0.51918676],\n",
       "       [ 1.03091645,  1.10520428,  0.06091705, ...,  0.74766556,\n",
       "         0.30132132,  0.81161461],\n",
       "       ...,\n",
       "       [ 1.56255086, -0.9048101 ,  2.36596127, ..., -0.02266782,\n",
       "         0.00814376, -0.0755863 ],\n",
       "       [ 0.11954317,  1.10520428, -0.61045506, ..., -0.79300119,\n",
       "        -0.3602469 ,  0.19057397],\n",
       "       [ 1.48660309, -0.9048101 ,  1.42604032, ...,  0.8478089 ,\n",
       "         1.655157  ,  2.31985616]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# fit training set\n",
    "scaler.fit(X_train)\n",
    "# transform the training set and test set\n",
    "scaler.transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.518311821269729"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso().fit(X_train, y_train)\n",
    "lasso.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4736545705189427"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Lasso scores are identical to those in part 6 but different from part 3. This is perhaps because we are using a Standard Scalar so we would expect the data to be different from that of the normalised data in part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lasso00001' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0d1bc37f5d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso00001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lasso alpha=0.0001\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lasso alpha=0.01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lasso alpha=1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lasso00001' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(lasso00001.coef_, '^', label=\"Lasso alpha=0.0001\")\n",
    "plt.plot(lasso001.coef_, 'v', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.legend(ncol=2,loc=(0,1.05))\n",
    "plt.ylim(-25,25)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 10\n",
    "Compute best value for α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.49008256025422375\n",
      "Best parameter for alpha: 0.001\n",
      "Test set score with best parameter: 0.4765818304860368\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for alpha in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    # for each parameter of alpha,\n",
    "    # train a a lasso\n",
    "    lasso = Lasso(alpha=alpha, max_iter=100000).fit(X_train,y_train)\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(lasso, X_train, y_train)\n",
    "    # compute mean cross-validation accuracy\n",
    "    score = np.mean(scores)\n",
    "    # if we got a better score, store the score and parameters\n",
    "    if score > best_score:\n",
    "      best_score = score\n",
    "      best_alpha = alpha\n",
    "# rebuild a model on the full training set\n",
    "lasso = Lasso(alpha=best_alpha, max_iter=100000).fit(X_train,y_train)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_score = lasso.score(X_test, y_test)\n",
    "print(\"Best CV score:\", best_score)\n",
    "print(\"Best parameter for alpha:\", best_alpha)\n",
    "print(\"Test set score with best parameter:\", lasso_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"diabetes.data\", delimiter=\"\t\", skip_header = 1,\n",
    "usecols=np.arange(10),)\n",
    "\n",
    "y = np.genfromtxt(\"diabetes.data\", delimiter=\"\t\", skip_header = 1,\n",
    "usecols=10, dtype='int')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS = calibration set\n",
    "X_TSP, X_CS, y_TSP, y_CS = train_test_split(X_train, y_train, random_state=1201, test_size=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46756957, -0.89356008,  0.17269573, ..., -0.09941834,\n",
       "         0.50925478, -0.16429168],\n",
       "       [ 0.78220046,  1.11911893, -0.59131094, ..., -0.87628112,\n",
       "        -0.35443511, -0.60853026],\n",
       "       [ 1.01065683,  1.11911893, -0.00707055, ...,  0.67744443,\n",
       "         0.2572422 ,  0.72418548],\n",
       "       ...,\n",
       "       [ 1.54372169, -0.89356008,  2.30742025, ..., -0.09941834,\n",
       "        -0.0333806 , -0.16429168],\n",
       "       [ 0.09683136,  1.11911893, -0.68119408, ..., -0.87628112,\n",
       "        -0.39856108,  0.10225147],\n",
       "       [ 1.46756957, -0.89356008,  1.3636473 , ...,  0.77843659,\n",
       "         1.59928049,  2.23459666]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_TSP)\n",
    "scaler.transform(X_TSP)\n",
    "scaler.transform(X_CS)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)\n",
    "nonconformity measure α = |y − ŷ|\n",
    "\n",
    "test error rate := total number of failures / test_set. Where failure is the prediction interval failing to cover the true label for that test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([275, 145, 158, 166, 101,  49, 161,  49, 248, 242, 288,  71, 168,\n",
       "       220,  71, 275,  65, 116, 182,  77,  84, 129, 214, 248, 142, 235,\n",
       "       162, 151, 280, 150,  51,  72, 219, 110,  66, 185,  48,  52, 202,\n",
       "       125, 178, 306,  72,  59, 163, 144, 303,  55,  94, 102, 302,  88,\n",
       "        91,  84, 148,  63, 141,  45,  93, 182, 118, 173,  72,  94,  66,\n",
       "       131,  97,  65, 181,  77,  40, 236,  55, 135, 202, 115, 101, 140,\n",
       "       245, 215,  71,  80, 131,  53, 136,  75, 122, 214, 268,  43,  97,\n",
       "       170, 102,  79, 181,  25, 237,  78, 283])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non conformity scoring\n",
    "def non_conformity(y, y_hat):\n",
    "    score = y - y_hat\n",
    "    score = math.fabs(score) #score = abs(score) for integer\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW PREDICTION STEP\n",
    "#compute nonconformity score for each in calbration set (CS) and test set (test)\n",
    "calibration_predictions = lasso.predict(X_CS)\n",
    "test_predictions = lasso.predict(X_test)\n",
    "\n",
    "calibration_set = []\n",
    "for label in range(len(calibration_predictions)):\n",
    "    calibration_set.append(non_conformity(y_CS[label], calibration_predictions[label]))\n",
    "    \n",
    "test_scores = []\n",
    "for label in range(len(test_predictions)):\n",
    "    test_scores.append(non_conformity(test_predictions[label], y_test[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank non conformity score from test sample and compute p_value\n",
    "def p_values(calibration_set_scores, samples_score):\n",
    "    p_value = 0\n",
    "    score = len(calibration_set_scores)+1\n",
    "    \n",
    "    for i in range(len(calibration_set_scores)):\n",
    "        if samples_score < calibration_set_scores[i]:\n",
    "            score -= 1\n",
    "            \n",
    "    p_value = score/(len(calibration_set_scores)+1)\n",
    "    return p_value\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALIBRATION STEP\n",
    "#compute p-values for each in test set\n",
    "p_values_list = []\n",
    "\n",
    "\n",
    "for score in range(len(test_predictions)):\n",
    "    p_values_list.append(p_values(calibration_set, test_predictions[score]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(epsilon = 0.95):\n",
    "    error = 0\n",
    "    \n",
    "    for p_value in range(len(p_values_list)):\n",
    "        if p_values_list[p_value] < epsilon:\n",
    "            error += 1\n",
    "    error_rate = error / len(test_predictions)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTS\n",
    "#(the predicion intervals paired with each TSP sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate at 5% threshold:  0.18018018018018017\n",
      "error rate at 20% threshold:  0.018018018018018018\n"
     ]
    }
   ],
   "source": [
    "#TEST ERROR RATE\n",
    "print('error rate at 5% threshold: ',compute_error_rate(0.95))\n",
    "print('error rate at 20% threshold: ',compute_error_rate(0.80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
